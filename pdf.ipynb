{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "0678b433-b1ef-4eb9-bc26-7e726c59c34d",
      "cell_type": "markdown",
      "source": "## Testing",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      }
    },
    {
      "id": "b3500c32-ed05-4d58-a9d6-d9ccd5da1f32",
      "cell_type": "code",
      "source": "import fitz  # PyMuPDF\n\n# Open the original PDF\ndoc = fitz.open(\"trojan_ok.pdf\")\n\n# Create a new PDF to hold the selected pages\nnew_doc = fitz.open()\n\n# Page numbers are 0-based, so 21st page is index 20\nnew_doc.insert_pdf(doc, from_page=0, to_page=10)  # inclusive range\n\n# Save the result\nnew_doc.save(\"trojan_1.pdf\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'fitz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfitz\u001b[39;00m  \u001b[38;5;66;03m# PyMuPDF\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Open the original PDF\u001b[39;00m\n\u001b[1;32m      4\u001b[0m doc \u001b[38;5;241m=\u001b[39m fitz\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrojan_ok.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fitz'"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 1
    },
    {
      "id": "38f98832-f2a6-4f3f-b82a-c769b7036021",
      "cell_type": "code",
      "source": "from openai import AzureOpenAI\n# Load environment variables\nendpoint = \"https://gpt-omnia-sweden-1.openai.azure.com/\"\napi_key = \"b767c605d00e470480e0105aad3ce76e\"\ndeployment = \"gpt-4o-mini-omnia-1\"\n\n\n# Initialize the Azure OpenAI client\nclient = AzureOpenAI(\n    azure_endpoint=endpoint,\n    api_key=api_key,\n    api_version=\"2024-02-01\",  # Or the latest API version you're using\n)\n\n# # Example: Creating a completion request\ncompletion = client.chat.completions.create(\n     model=deployment,  # This should be your deployment name\n     messages=[{\"role\": \"user\", \"content\": \"Tell me a joke\"}]\n)\nassistant_message = completion.choices[0].message.content.strip()\nassistant_message",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'openai'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAI\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Load environment variables\u001b[39;00m\n\u001b[1;32m      3\u001b[0m endpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://gpt-omnia-sweden-1.openai.azure.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 2
    },
    {
      "id": "c34314cc-b64f-448f-ad1c-3531de2a7344",
      "cell_type": "code",
      "source": "prompt = \"\"\"\nYou are a creative learning assistant. Your task is to generate an engaging, gamified storytelling learning experience using only the information from the provided PDF. Do not use any external knowledge.\n\nCreate a short interactive story (around 3‚Äì5 scenes) where students go through a journey and must answer open-ended questions at each step to progress.\n\nEach scene should include:\n- A short, engaging narrative.\n- One question based ONLY on the content from the PDF.\n- No answer options ‚Äî the student will type their own answer.\n- A clear prompt to the user like: \"What is your answer?\" and then wait for input.\n\nAfter the student replies with their answer, the assistant should:\n- Check the answer against the PDF.\n- Say whether it's correct or incorrect.\n- Briefly explain the correct answer using only PDF content.\n\nStory Requirements:\n- Use simple, engaging language suitable for students.\n- The theme of the story can be fun (e.g. fantasy, mystery, sci-fi), but all educational content must come strictly from the PDF.\n- Avoid using any information not found in the PDF.\n\nFormat:\nScene #: [Scene Title]\nNarrative: [Story content]\nQuestion: [Ask a clear, open-ended question based on the PDF]\nPrompt: \"What is your answer?\"\n\n(Wait for user input, then proceed to check and explain.)\n\"\"\"",
      "metadata": {},
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "ef424489-6d64-4735-9979-b3ee9755a54a",
      "cell_type": "code",
      "source": "import fitz  # PyMuPDF\n\ndef extract_text_from_pdf(pdf_path):\n    doc = fitz.open(pdf_path)\n    text = \"\"\n    for page in doc:\n        text += page.get_text()\n    doc.close()\n    return text\n\n# Load PDF content\npdf_text = extract_text_from_pdf(\"trojan_1.pdf\")\n\n# Truncate or chunk the PDF content if it's too large\nmax_chars = 4000  # Adjust based on model context length and prompt size\npdf_text = pdf_text[:max_chars]",
      "metadata": {},
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "7ff2c10a-1b17-41ea-abfa-41f684630a9e",
      "cell_type": "code",
      "source": "import tiktoken\ntokenizer = tiktoken.encoding_for_model(\"gpt-4o-mini\")\ntokens = tokenizer.encode(pdf_text)\nnum_tokens = len(tokens)\nnum_tokens",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "973"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 3
    },
    {
      "id": "81d387bc-f7c0-4f6b-b274-a7834f5b4da7",
      "cell_type": "code",
      "source": "# Combine PDF content with your prompt\ncombined_prompt = f\"\"\"\nUse only the following content from the PDF for your responses:\n\n\\\"\\\"\\\"\n{pdf_text}\n\\\"\\\"\\\"\n\nNow, based on the above, follow the instructions below.\n\n{prompt}\n\"\"\"\n\n# Call Azure OpenAI ChatCompletion\nresponse = client.chat.completions.create(\n    model=deployment,  # Your deployment name\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": (\n                \"You are a creative and educational assistant. Your task is to design an interactive, gamified storytelling experience for students, \"\n                \"based strictly on the content of a provided PDF. Do not use any external knowledge. In each scene, guide the student through a story, \"\n                \"ask open-ended questions based only on the PDF, and wait for their input before evaluating the response.\"\n            )\n        },\n        {\n            \"role\": \"user\",\n            \"content\": combined_prompt\n        }\n    ],\n    max_tokens=1000,  # You can increase this depending on story length\n    temperature=0.7,  # Slightly more creative\n    top_p=1,\n    n=1,\n    stop=None,\n)\n\n# Get and print the output\ngenerated_text = response.choices[0].message.content.strip()\nprint(\"Generated:\")\nprint(generated_text)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Generated:\n,**Scene 1: The Spark of Conflict**  \n,Narrative: In ancient Greece, a beautiful woman named Helen was taken from her husband, Menelaus, the king of Sparta. This act sparked a legendary war that would be told for generations. The Achaeans, known as the Greeks, gathered their forces to march against the city of Troy, where Helen had been taken. As the warriors prepared for battle, a sense of fate hung in the air. What could have driven Paris of Troy to take such a bold step?  \n,Question: Why did the Achaeans wage war against the city of Troy?  \n,Prompt: \"What is your answer?\"  \n,\n,(Wait for user input, then proceed to check and explain.)\n"
        }
      ],
      "execution_count": 5
    },
    {
      "id": "a50ef718-3115-40f4-8984-b8b5e743ab51",
      "cell_type": "code",
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üéÆ  Gamified Learning Journey\")\nprint(\"=\"*80 + \"\\n\")\n\nprint(generated_text.strip())\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"üìù  Your Turn: Please answer the question above to continue the journey!\")\nprint(\"=\"*80 + \"\\n\")\n",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n,================================================================================\n,üéÆ  Gamified Learning Journey\n,================================================================================\n,\n,**Scene 1: The Call to Adventure**  \n,Narrative: In a distant land where myths come alive, you find yourself in ancient Greece, just before a great conflict known as the Trojan War. The air is filled with tension as Achaeans prepare to march against the city of Troy, all because Paris of Troy has taken Helen, the wife of Menelaus, the king of Sparta. You stand at the edge of the battlefield, feeling the weight of history around you. Will you join the Achaeans in their quest?  \n,\n,Question: Why did the Achaeans go to war against Troy?  \n,Prompt: \"What is your answer?\"  \n,\n,(Wait for user input.)\n,\n,================================================================================\n,üìù  Your Turn: Please answer the question above to continue the journey!\n,================================================================================\n,\n"
        }
      ],
      "execution_count": 36
    },
    {
      "id": "fa004ff4-f275-462d-b97f-15a23de44c47",
      "cell_type": "code",
      "source": "def predict(input, history=[]):\n    # Define instructions and knowledge base\n    instruction = 'Instruction: given a dialog context, you need to respond empathically'\n    knowledge_base = {\n        \"what is google colab\": (\"Google Colab, or 'Colaboratory,' is a free cloud service provided by Google that allows you to write and execute Python code in a web-based environment. \"\n                                 \"It's particularly useful for data science, machine learning, and AI projects. Key features include no setup required, free access to GPUs and TPUs, \"\n                                 \"interactive notebooks, and integration with Google Drive.\")\n    }\n\n    # Flatten the history and append the new input\n    s = list(sum(history, ()))\n    s.append(input)\n    dialog = ' EOS '.join(s)\n    query = f\"{instruction} [CONTEXT] {dialog}\"\n\n    # Check if the input matches any knowledge base entries\n    input_lower = input.lower()\n    if input_lower in knowledge_base:\n        response = knowledge_base[input_lower]\n    else:\n        # Generate a response using the model\n        new_user_input_ids = tokenizer.encode(f\"{query}\", return_tensors='pt')\n        output = model.generate(new_user_input_ids, min_length=8, max_length=64, top_p=0.9, do_sample=True).tolist()\n        response = tokenizer.decode(output[0], skip_special_tokens=True)\n\n    # Update the history\n    history.append((input, response))\n\n    return history, history",
      "metadata": {},
      "outputs": [],
      "execution_count": 40
    },
    {
      "id": "18612abf-cf17-40c3-ad2a-1a4ca3b27121",
      "cell_type": "code",
      "source": "import openai\n\nresponse = client.chat.completions.create(\n    model=deployment,  # Your deployment name\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": (\n                \"You are a creative and educational assistant. Your task is to design an interactive, gamified storytelling experience for students, \"\n                \"based strictly on the content of a provided PDF. Do not use any external knowledge. In each scene, guide the student through a story, \"\n                \"ask open-ended questions based only on the PDF, and wait for their input before evaluating the response.\"\n            )\n        },\n        {\n            \"role\": \"user\",\n            \"content\": combined_prompt\n        }\n    ],\n    max_tokens=1000,  # You can increase this depending on story length\n    temperature=0.7,  # Slightly more creative\n    top_p=1,\n    n=1,\n    stop=None,\n)\n\n# Print the response\nresponse.choices[0].message.content.strip()\nprint(response.choices[0].message.content.strip())",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "**Scene 1: The Call to Adventure**  \n,Narrative: You find yourself in ancient Greece, where the sun shines brightly over the bustling city of Sparta. Suddenly, a messenger rushes in, breathless and alarmed. \"The beautiful Helen has been taken by Paris of Troy!\" he shouts. This act has angered King Menelaus, and he gathers the greatest warriors to sail to Troy and reclaim her. You feel a stirring in your heart ‚Äî could you join them on this legendary quest?  \n,Question: Why did the Achaeans go to war against the city of Troy?  \n,Prompt: \"What is your answer?\"  \n,\n,---\n,\n,(Wait for user input, then proceed to check and explain.)\n"
        }
      ],
      "execution_count": 42
    },
    {
      "id": "e1d16a36-1b1f-4fbf-b0e1-dbbe94569213",
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "efd57171-731c-440e-bbff-f41fc5a6de8d",
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0a4d88ba-d54b-484d-ba9e-71d7aa7b8392",
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8ee3db12-17fb-4b35-8cb3-da6411d002c9",
      "cell_type": "markdown",
      "source": "## Main Code",
      "metadata": {}
    },
    {
      "id": "99bc7422-9f54-44ad-a861-c79255b1621b",
      "cell_type": "code",
      "source": "import json\nimport gradio as gr\nimport fitz  # PyMuPDF\nfrom openai import AzureOpenAI\nimport re\nimport copy\n# Load environment variables\nendpoint = \"https://gpt-omnia-sweden-1.openai.azure.com/\"\napi_key = \"√¨√¨√¨\"\ndeployment = \"gpt-4o-mini-omnia-1\"\n\n\n# Initialize the Azure OpenAI client\nclient = AzureOpenAI(\n    azure_endpoint=endpoint,\n    api_key=api_key,\n    api_version=\"2024-02-01\",  # Or the latest API version you're using\n)",
      "metadata": {},
      "outputs": [],
      "execution_count": 1
    },
    {
      "id": "8dc2f601-5d58-4618-917b-726907f59b9b",
      "cell_type": "code",
      "source": "def extract_text_from_pdf(pdf_path):\n    doc = fitz.open(pdf_path)\n    text = \"\"\n    for page in doc:\n        text += page.get_text()\n    doc.close()\n    return text\n\n# Load PDF content\npdf_text = extract_text_from_pdf(\"trojan_1.pdf\")\n\n# Truncate or chunk the PDF content if it's too large\nmax_chars = 4000  # Adjust based on model context length and prompt size\npdf_text = pdf_text[:max_chars]",
      "metadata": {},
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "91e22a76-f082-4aa8-a55a-2d133c3edbfb",
      "cell_type": "code",
      "source": "# Main gamified assistant history\nchat_history = [\n]\n\n# Secondary helper assistant history\nhelper_chat_history = [\n]\n\nanswer_question_list = [\n]\n\n# Main story handler\ndef chat_with_story(user_input):\n    chat_history.append({\"role\": \"user\", \"content\": user_input})\n\n    \n    assistant_question = chat_history[-2][\"content\"]\n    user_answer = chat_history[-1][\"content\"]\n        \n    evaluator_prompt = f\"\"\"\n    You are the **evaluator agent** in a multi-agent educational system.\n    \n    Your task is to assess the correctness of the student's answer using **only the content provided in the PDF**. You must not rely on any external knowledge.\n    \n    Below is the relevant information:\n    \n    üìö PDF Content:\n    \\\"\\\"\\\"\n    {pdf_text}\n    \\\"\\\"\\\"\n    \n    ü§ñ Assistant's Question:\n    {assistant_question}\n    \n    üë§ Student's Answer:\n    {user_answer}\n    \n    ---\n    \n    üéì Instructions:\n    \n    1. Compare the student's answer to what is stated or implied in the PDF.\n    2. If the answer aligns with the PDF, it is correct. If it is incomplete, incorrect, or fabricated, mark it as incorrect.\n    3. Extract the most accurate answer from the PDF (i.e., the correct answer).\n    4. Assign a **score** between 0 and 1:\n       - `1` for completely correct\n       - `0` for incorrect\n       - Any value in between (e.g., 0.5) for partially correct answers\n    \n    5. Output your evaluation in this strict JSON format:\n    \n    ```json\n    {{\n      \"AssistantQuestion\": \"<Restate the original assistant question>\",\n      \"UserAnswer\": \"<Restate the user's answer>\",\n      \"CorrectAnswer\": \"<The correct answer based strictly on the PDF>\",\n      \"Explanation\": \"<Explain why the answer is correct or incorrect>\",\n      \"Judgment\": \"Correct\" or \"Incorrect\",\n      \"Score\": <float between 0 and 1>\n    }}\n    \n    ‚ö†Ô∏è Notes:\n    \n    - Use short quotes from the PDF if helpful.\n    \n    - Do not create new story content or repeat the narrative.\n    \n    - Only output the JSON ‚Äî no extra commentary or formatting.\n    \"\"\"\n    chat_with_evaluation = copy.deepcopy(chat_history)\n    evaulation_judg = \"tmp\"\n    \n    if len(chat_history) > 3:\n        response = client.chat.completions.create(\n            model=deployment,\n            messages=[{\"role\": \"user\", \"content\": evaluator_prompt}],\n            max_tokens=1000,\n            temperature=0.1,\n            top_p=1\n        )\n            \n        evaluation_answer = response.choices[0].message.content.strip()\n        json_pattern = re.compile(r'(\\{.*\\})', re.DOTALL)\n        match = json_pattern.search(evaluation_answer)\n        evaluation_str = match.group(1)\n        json_evaulation = json.loads(evaluation_str)\n        answer_question_list.append(json_evaulation)\n        chat_with_evaluation.append({\"role\": \"assistant\", \"content\": f\"[Evaluator Agent] {evaluation_str}\"})\n    \n        evaulation_judg = json_evaulation[\"Judgment\"]\n\n    response = client.chat.completions.create(\n        model=deployment,\n        messages=chat_with_evaluation,\n        max_tokens=1000,\n        temperature=0.7,\n        top_p=1\n    )\n    reply = response.choices[0].message.content.strip()\n    chat_history.append({\"role\": \"assistant\", \"content\": f\"[Assistant Agent] {reply}\"})\n    \n    if(evaulation_judg == \"Incorrect\"):\n        helper_chat_history.append({\"role\": \"assistant\", \"content\": f\"[Evaluator Agent] {evaluation_str}\"})\n        helper_response = chat_with_helper(user_input, include_user=True)\n        return \"\", chat_history[1:], helper_response\n    return \"\", chat_history[1:], helper_chat_history[1:]\n\n# Helper assistant handler\ndef chat_with_helper(user_input, include_user=True):\n    if include_user:\n        helper_chat_history.append({\"role\": \"user\", \"content\": f\"[User Answer] {user_input}\"})\n\n    response = client.chat.completions.create(\n        model=deployment,\n        messages=helper_chat_history,\n        max_tokens=500,\n        temperature=0.3,\n        top_p=1\n    )\n    reply = response.choices[0].message.content.strip()\n    helper_chat_history.append({\"role\": \"assistant\", \"content\": f\"[Helper Agent] {reply}\"})\n    #return \"\", helper_chat_history[1:]\n    return \"\", helper_chat_history[1:]\n\n# Start story on load\ndef start_story():\n\n    helper_system_prompt = \"\"\"\n    You are a helpful learning assistant designed to support students in reasoning their way toward correct answers without simply giving the solution.\n    \n    You will receive structured evaluation data in this format:\n    \n    {\n      \"AssistantQuestion\": \"<Restate the original assistant question>\",\n      \"UserAnswer\": \"<Restate the user's answer>\",\n      \"CorrectAnswer\": \"<The correct answer based strictly on the PDF>\",\n      \"Explanation\": \"<Explain why the answer is correct or incorrect>\",\n      \"Judgment\": \"Correct\" or \"Incorrect\",\n      \"Score\": <float between 0 and 1>\n    }\n    \n    Your role is to:\n    1. Understand the assistant's original question and the concept being tested.\n    2. Reflect on the student‚Äôs answer and the evaluator's explanation.\n    3. **Help the student improve their understanding** of the topic through:\n       - Socratic questioning ü§î\n       - Gentle clues and scaffolding üí°\n       - Encouraging deeper thinking üß†\n    \n    **Do not immediately reveal the correct answer.** Instead:\n    - If the answer is partially correct (Score between 0.3‚Äì0.7), encourage refinement.\n    - If incorrect, prompt the student to rethink the question using clues from the concept.\n    - If correct, briefly reinforce the reasoning and encourage progress to the next scene.\n    \n    Tone: supportive, motivational, and adaptive. Use second-person language (\"you\") and keep the student engaged without frustration. Your goal is to help them **learn through discovery**, not just receive answers.\n    \n    Never output the correct answer directly unless explicitly instructed.\n    \"\"\"\n    \n    initial_prompt = f\"\"\"\n    You are an intelligent educational agent. Your task is to analyze the provided PDF content (in the variable `pdf_text`) and identify the academic or cognitive skills that can be directly assessed based on its content.\n    \n    Instructions:\n    \n    1. Carefully analyze the entire content in `pdf_text`.\n    2. Identify only the skills that are explicitly testable using the actual content. Do not guess or include generic skills unless they are clearly supported by the text.\n    3. Each skill must be categorized using **Bloom's Taxonomy**, using one of the following levels:\n       - Remember\n       - Understand\n       - Apply\n       - Analyze\n       - Evaluate\n       - Create\n    4. Choose the most appropriate Bloom‚Äôs level for each skill based on how a student would be challenged using the PDF content.\n    \n    ---\n    \n    Output Format (strict JSON):\n    \n    ```json\n    {{\n      \"Skills\": [\n        \"Historical fact recall ‚Äì Bloom: Remember\",\n        \"Cause and effect reasoning ‚Äì Bloom: Analyze\",\n        \"Source evaluation ‚Äì Bloom: Evaluate\"\n      ]\n    }}\n    \n    \n    Use only the content in {pdf_text}. Do not use any outside knowledge. Make sure the output is in valid JSON and includes only those three fields.\n    \"\"\"\n    response = client.chat.completions.create(\n        model=deployment,\n        messages=[{\"role\": \"user\", \"content\": initial_prompt}],\n        max_tokens=500,\n        temperature=0.3,\n        top_p=1\n    )\n    generated_text = response.choices[0].message.content.strip()\n    json_pattern = re.compile(r'(\\{.*\\})', re.DOTALL)\n    match = json_pattern.search(generated_text)\n    json_str = match.group(1)\n    json_init = json.loads(json_str)\n\n    init_skills = json_init[\"Skills\"]\n\n    combined_prompt = f\"\"\"\n    You are in the role of the **assistant** in a multi-agent educational system.\n    \n    Your task is to generate a gamified, interactive storytelling experience based strictly on the content of the provided PDF. Another agent, called the **evaluator**, will be responsible for judging the correctness of the student's answers. You must NOT evaluate answers yourself.\n    \n    Here is the source content you must base your story on:\n    \n    \\\"\\\"\\\"\n    {pdf_text}\n    \\\"\\\"\\\"\n    \n    The student should be tested on the following academic skills (mapped to Bloom's Taxonomy):\n    \n    {init_skills}\n    \n    Now, using only the information from the PDF, create a highly engaging learning journey.\n    \n    ### Instructions for the Assistant:\n    \n    - You are the storyteller and guide.\n    - Write in **second-person perspective (\"you\")**, making the student the main character.\n    - Make the story immersive and gamified ‚Äî e.g., a quest üß≠, survival ‚öîÔ∏è, time-travel mystery ‚è≥, or sci-fi journey üöÄ.\n    - Use **emojis** to enhance emotion, atmosphere, and decision points: üìúüß†üß©‚öñÔ∏èüî•\n    \n    ### Each scene must contain:\n    - A vivid, engaging narrative grounded strictly in the PDF.\n    - One open-ended question tied to the skills above.\n    - A prompt: \"üìù What is your answer?\"\n    \n    After the user responds:\n    - The **evaluator agent** will assess whether the answer is correct, using only the PDF content.\n    - You must then continue the story based on the evaluator's judgment:\n    \n        - ‚úÖ If the evaluator says the answer is correct:\n            - Congratulate the student with excitement and progression in the story.\n            - Use celebratory emojis (üéâüöÄüü¢) and move the story forward.\n    \n        - ‚ùå If the evaluator says the answer is incorrect:\n            - Guide the student with encouragement.\n            - Clarify the correct concept using only what the evaluator said.\n            - Help them recover and continue the story with support (üí°üìòüîÑ).\n    \n    You must never guess, invent, or judge correctness yourself. Always wait for the evaluator's decision before proceeding.\n    \n    Your goal is to make the learning journey feel immersive, personal, and adaptive ‚Äî just like a dynamic learning game üéØ.\n    \"\"\"\n    if len(chat_history) == 0 and len(helper_chat_history) == 0:\n        helper_chat_history.append({\"role\": \"system\", \"content\": helper_system_prompt})\n    \n        chat_history.append({\"role\": \"system\", \"content\": combined_prompt})\n    \n        intro_message = \"Welcome to the story adventure! Let's begin your journey.\"\n        help_intro = \"Hey, we‚Äôre your colleagues ‚Äî let‚Äôs talk through the topic you‚Äôre stuck on together.\"\n        \n        chat_history.append({\"role\": \"assistant\", \"content\": f\"[Assistant Agent] {intro_message}\"})\n        helper_chat_history.append({\"role\": \"assistant\", \"content\": f\"[Helper Agent] {help_intro}\"})\n\n    return chat_history[1:], helper_chat_history[1:]\n\n# Gradio UI\nwith gr.Blocks() as demo:\n    gr.Markdown(\"## üß† Main Learning Chat (Gamified Story)\")\n\n    with gr.Row():\n        chatbot = gr.Chatbot(\n            label=\"Gamified Story Assistant\",\n            type=\"messages\",\n            height=600,\n            avatar_images=[\"user.jpg\", \"assistant.jpg\"]  # üë§ ü§ñ\n        )\n\n        helpbot = gr.Chatbot(\n            label=\"Help Assistant\",\n            type=\"messages\",\n            height=350,\n            avatar_images=[\"user.jpg\", \"wizard.jpg\"]  # üë§ üßô\n        )\n\n    with gr.Row():\n        msg = gr.Textbox(label=\"Your Answer\", placeholder=\"Type your story answer here...\")\n        helper_input = gr.Textbox(label=\"Ask for Help\", placeholder=\"How do I progress?\")\n\n    msg.submit(chat_with_story, [msg], [msg, chatbot, helpbot])\n    helper_input.submit(chat_with_helper, [helper_input], [helper_input, helpbot])\n\n    demo.load(start_story, outputs=[chatbot, helpbot])\n",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2217e407-2df9-45c1-b6b2-1a71323de38b",
      "cell_type": "code",
      "source": "demo.launch(debug=True, share=True)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "* Running on local URL:  http://127.0.0.1:7860\n,* Running on public URL: https://eacd0b651cadb8eed7.gradio.live\n,\n,This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://eacd0b651cadb8eed7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": null
    },
    {
      "id": "606b24cb-549b-48e1-9e34-39a0b6954aaf",
      "cell_type": "code",
      "source": "answer_question_list",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'AssistantQuestion': 'What event triggered the Trojan War between the Achaeans and the city of Troy?',\n",
              "  'UserAnswer': 'paris kidnapped wife of sparta',\n",
              "  'CorrectAnswer': 'The war was waged by the Achaeans (Greeks) against the city of Troy after Paris of Troy took Helen from her husband Menelaus, king of Sparta.',\n",
              "  'Explanation': \"The student's answer captures the essence of the event that triggered the Trojan War, specifically mentioning Paris and the kidnapping of Helen. However, it lacks clarity and completeness, as it does not specify that Helen was taken from her husband Menelaus, which is a crucial part of the context.\",\n",
              "  'Judgment': 'Incorrect',\n",
              "  'Score': 0.5}]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 18
    },
    {
      "id": "4027517d-5d0b-4978-bb5a-06c22fb8f5e9",
      "cell_type": "code",
      "source": "chat_history",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}